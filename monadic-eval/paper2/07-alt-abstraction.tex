\section{An Alternative Abstraction}\label{s:alt-abstraction}

\begin{figure} %{-{
\rfloat{⸨precise-δ@⸩}
\begin{lstlisting}
¦ (define (δ . ovs)
¦   (match ovs
¦     [`(add1 ,(? number? n))  (return (add1 n))]
¦     [`(+    ,(? number? n₁)
¦             ,(? number? n₂)) (return (+ n₁ n₂))]
¦     ...
¦     [`(add1 ,_) (return 'N)]
¦     [`(+ ,_ ,_) (return 'N)]
¦     ...
¦     ))
¦ (define (zero? v)
¦   (match v
¦     ['N (mplus (return #t) (return #f))]
¦     [_  (return (zero? v))]))
\end{lstlisting}
\figskip\rfloat{⸨store-crush@⸩}
\begin{lstlisting}
¦ (define (find a)
¦   (do σ ← get-store
¦       (for/monad+ ([v (σ a)])
¦         (return v))))
¦ (define (number*? n) (or (eq? 'N n) (number? n)))
¦ (define (crush v vs)
¦   (if (number*? v)
¦       (set-add 
¦         (for/set ([v* vs] #:unless (number*? v*)) 
¦           v*) 
¦         'N)
¦       (set-add vs v)))
¦ (define (ext a v)
¦   (update-store
¦    (λ (σ)
¦      (if (∈ a σ)
¦          (σ a (crush v (σ a)))
¦          (σ a (set v))))))
\end{lstlisting}
\caption{An Alternative Abstraction for Precise Primitives}
\label{f:pres-delta}
\end{figure} %}-}

In this section, we demonstrate how easy it is to experiment with alternative
abstraction strategies by swapping out components.  In particular we look at an
alternative abstraction of primitive operations and store joins.

Figure~\ref{f:pres-delta} defines two new components: ⸨precise-δ@⸩ and
⸨store-crush@⸩.  The first is an alternative interpretation for primitive
operations that is \emph{precision preserving}.  Unlike ⸨δ^@⸩, it does not
introduce abstraction, it merely propagates it.  When two concrete
numbers are added together, the result will be a concrete number, but if either
number is abstract then the result is abstract.

This interpretation of primitive operations clearly doesn't impose a finite
abstraction on its own, because the state space for concrete numbers is
infinite. If ⸨precise-δ@⸩ is linked with the ⸨store-nd@⸩ implementation of the
store, termination is therefore not guaranteed.  

The ⸨store-crush@⸩ operations are designed to work with ⸨precise-δ@⸩ by
performing \emph{widening} when joining multiple concrete values into the
store. This abstraction offers a high-level of precision; for example,
``straight-line'' arithmetic operations are computed with full precision:
ℑ⁅
¦ > (* (+ 3 4) 9)
ℑ,
¦ '(63)
ℑ⁆
Even linear binding and arithmetic preserves precision:
ℑ⁅
¦ > ((λ (x) (* x x)) 5)
ℑ,
¦ '(25)
ℑ⁆
It's only when the approximation of binding structure comes in to
contact with base values that we see a loss in precision:
ℑ⁅
¦ > (let f (λ (x) x)
¦     (* (f 5) (f 5)))
ℑ,
'(N)
ℑ⁆
This combination of ⸨precise-δ@⸩ and ⸨store-crush@⸩ allows termination for most
programs, but still not all. In the following example, ⸨id⸩ is eventually
applied to a widened argument ⸨'N⸩, which makes both conditional branches
reachable. The function returns ⸨0⸩ in the base case, which is propagated to
the recursive call and given to ⸨add1⸩, which yields the concrete answer ⸨1⸩.
This results in a cycle where ⸨add1⸩ returns ⸨2⸩, ⸨3⸩, ⸨4⸩ when applied to ⸨1⸩,
⸨2⸩, ⸨3⸩, etc.
ℑ⁅
¦ > (rec id (λ (n) (if0 n 0 (add1 (id (sub1 n)))))
¦     (id 3))
ℑ,
¦ timeout
ℑ⁆
To ensure termination for all programs, we assume all references to primitive
operations are $η$-expanded, so that store-allocations also take place at
primitive applications, ensuring widening at repeated bindings. The above
program terminates with this desugaring:
ℑ⁅
¦ > (rec id (λ (n) (if0 n 0 ((λ (i) (add1 i))
¦                            (id ((λ (j) (sub1 j)) n)))))
¦     (id 3))
ℑ,
¦ '(0 N)
ℑ⁆
In fact, all programs terminate when using ⸨precise-δ@⸩, ⸨store-crush@⸩ and
«η»-expanded primitives, which means we have a achieved a computable and
uniquely precise abstract interpreter.

\begin{figure} %{-{
\rfloat{⸨symbolic-monad@⸩}
\begin{lstlisting}
¦ (define-monad
¦   (ReaderT (FailT (StateT (StateT (NondetT ID))))))
\end{lstlisting}
\figskip\rfloat{⸨ev-symbolic@⸩}
\begin{lstlisting}
¦ (define (((ev-symbolic ev₀) ev) e)
¦   (match e
¦     [(sym x) (return x)]
¦     [e       ((ev₀ ev) e)]))
\end{lstlisting}
\figskip\rfloat{⸨δ-symbolic@⸩}
\begin{lstlisting}
¦ (define (δ . ovs)
¦   (match ovs
¦     ...
¦     [(list '/ v₀ v₁)
¦      (do z? ← (zero? v₁)
¦          (cond
¦           [z? fail]
¦           [(and (number? v₀) (number? v₁))
¦            (return (/ v₀ v₁))]
¦           [else
¦            (return `(/ ,v₀ ,v₁))]))]
¦     [(list '¬ 0) 1]
¦     ...
¦     ))
¦ (define (zero? v)
¦   (do φ ← get-path-cond
¦       (match v
¦         [(? number? n) (return (= 0 n))]
¦         [v #:when (∈ v φ) (return #t)]
¦         [v #:when (∈ `(¬ ,v) φ) (return #f)]
¦         [`(¬ ,v′) (do a ← (zero? v′)
¦                       (return (not a)))]
¦         [v (mplus (do (refine v)
¦                       (return #t))
¦                   (do (refine `(¬ ,v))
¦                       (return #f)))])))
\end{lstlisting}
\caption{Symbolic Execution Variant}
\label{f:symbolic}
\end{figure} %}-}

Here we see one of the strengths of the extensible, definitional approach to
abstract interpreters. The combination of added precision and widening is
encoded quite naturally. In contrast, it's hard to imagine how such a
combination could be formulated as, say, a constraint-based flow analysis.
