\section{Detecting Cycles with a Cache}\label{s:cache}

At this point, the interpreter obtained by linking together â¸¨monad^@â¸©, â¸¨Î´^@â¸©,
â¸¨alloc^@â¸© and â¸¨store-nd@â¸© components will only ever visit a finite number of
configurations for a given program. A configuration (â¸¨Ï‚â¸©) consists of an
expression (â¸¨eâ¸©), environment (â¸¨Ïâ¸©) and store (â¸¨Ïƒâ¸©). This configuration is
finite because: expressions are finite in the given program; environments are
maps from variables (again, finite in the program) to addresses; the addresses
are finite thanks to â¸¨alloc^â¸©; the store maps addresses to sets of values; base
values are abstracted to a finite set by â¸¨Î´^â¸©; and closures consist of an
expression and environment, which are both finite.

Although the interpreter will only ever see a finite set of inputs, it
\emph{doesn't know it}.  A simple loop will cause the interpreter to diverge:
â„‘â…
Â¦ > (rec f (Î» (x) (f x)) (f 0))
â„‘,
Â¦ timeout
â„‘â†
To solve this problem, we introduce a \emph{cache} (â¸¨Â¢â¸¢inâ¸£â¸©) as input to the
algorithm, which maps from configurations (â¸¨Ï‚â¸©) to sets of value-and-store
pairs (â¸¨vÃ—Ïƒâ¸©). When a configuration is reached for the second time, rather than
re-evaluating the expression and entering an infinite loop, the result is
looked up from â¸¨Â¢â¸¢inâ¸£â¸©, which acts as an oracle. It is important that the cache
is used co-inductively: it is only safe to use â¸¨Â¢â¸¢inâ¸£â¸© as an oracle so long as
some progress has been made first. 

The results of evaluation are then stored in an output cache (â¸¨Â¢â¸¢outâ¸£â¸©), which
after the end of evaluation is â€œmore definedâ€ than the input cache (â¸¨Â¢â¸¢inâ¸£â¸©),
again following a co-inductive argument. The least fixed-point of â¸¨Â¢âºâ¸© of an
evaluator which transforms an oracle â¸¨Â¢â¸¢inâ¸£â¸© and outputs a more defined oracle
â¸¨Â¢â¸¢outâ¸£â¸© is then a sound approximation of the program, because it
over-approximate all finite-number of unrollings of the unfixed evaluator. We
formalize this co-inductive process in Section~\ref{s:formalism} and prove it
sound; in this section we instead focus on the intuition and implementation for
the algorithm.

\begin{figure} %{-{
\rfloat{â¸¨monad-cache@â¸©}
\begin{flalign*}
            & ğ”¥â¸¨(define-monad (â¸©\!\up{ğ”¥â¸¨ReaderTâ¸©}â¸¢envâ¸£\ ğ”¥â¸¨(â¸©\!\up{ğ”¥â¸¨FailTâ¸©}â¸¢errorsâ¸£
& \\[-0.5em]& â£â£ğ”¥â¸¨(â¸©\!\up{ğ”¥â¸¨StateTâ¸©}â¸¢storeâ¸£\ ğ”¥â¸¨(â¸©\!\up{ğ”¥â¸¨NondetTâ¸©}â¸¢branchingâ¸£\ ğ”¥â¸¨(â¸©\!\up{ğ”¥â¸¨ReaderTâ¸©}â¸¢in-cacheâ¸£\ ğ”¥â¸¨(â¸©\!\up{ğ”¥â¸¨StateT+â¸©}â¸¢out-cacheâ¸£\ ğ”¥â¸¨ID)))))))â¸©
& \end{flalign*}
\figskip\rfloat{â¸¨ev-cache@â¸©}
\begin{lstlisting}
Â¦ (define (((ev-cache evâ‚€) ev) e)
Â¦   (do Ï â† ask-env
Â¦       Ïƒ â† get-store
Â¦       Ï‚ â‰” (list e Ï Ïƒ)
Â¦       Â¢â¸¢outâ¸£ â† get-cache-out
Â¦       (if (âˆˆ Ï‚ Â¢â¸¢outâ¸£)
Â¦           (for/monad+ ([vÃ—Ïƒ (Â¢â¸¢outâ¸£ Ï‚)])
Â¦             (do (put-store (cdr vÃ—Ïƒ))
Â¦                 (return (car vÃ—Ïƒ))))
Â¦           (do Â¢â¸¢inâ¸£ â† ask-cache-in
Â¦               vÃ—Ïƒâ‚€ â‰” (if (âˆˆ Ï‚ Â¢â¸¢inâ¸£) (Â¢â¸¢inâ¸£ Ï‚) âˆ…)
Â¦               (put-cache-out (Â¢â¸¢outâ¸£ Ï‚ vÃ—Ïƒâ‚€))
Â¦               v  â† ((evâ‚€ ev) e)
Â¦               Ïƒâ€² â† get-store
Â¦               vÃ—Ïƒâ€² â‰” (cons v Ïƒâ€²)
Â¦               (update-cache-out
Â¦                 (Î» (Â¢â¸¢outâ¸£) 
Â¦                   (Â¢â¸¢outâ¸£ Ï‚ (set-add (Â¢â¸¢outâ¸£ Ï‚) vÃ—Ïƒâ€²))))
Â¦               (return v)))))
\end{lstlisting}
\caption{Co-inductive Caching Algorithm}
\label{f:caching}
\end{figure} %}-}

The co-inductive caching algorithm is shown in Figure~\ref{f:caching}, along
with the monad transformer stack â¸¨monad-cache@â¸© which has two new components:
â¸¨ReaderTâ¸© for the input cache â¸¨Â¢â¸¢inâ¸£â¸©, and â¸¨StateT+â¸© for the output cache
â¸¨Â¢â¸¢outâ¸£â¸©. We use a â¸¨StateT+â¸© instead of â¸¨WriterTâ¸© monad transformer in the
output cache so it can double as tracking the set of seen states. The â¸¨+â¸© in
â¸¨StateT+â¸© signifies that caches for multiple non-deterministic branches will be
merged automatically, producing a set of results and a single cache, rather
than a set of results paired with individual caches.

In the algorithm, when a configuration â¸¨Ï‚â¸© is first encountered, we place an
entry in the output cache mapping â¸¨Ï‚â¸© to Â«ğ”¥â¸¨(Â¢â¸¢inâ¸£â¸©\ ğ”¥â¸¨Ï‚)â¸©Â», which is the
â€œoracleâ€ result. Also, whenever we finish computing the result â¸¨vÃ—Ïƒâ¸© of
evaluating a configuration â¸¨Ï‚â¸©, we place an entry in the output cache mapping
â¸¨Ï‚â¸© to â¸¨vÃ—Ïƒâ€²â¸©. Finally, whenever we reach a configuration â¸¨Ï‚â¸© for which a
mapping in the output cache exists, we use it immediately, â¸¨returnâ¸©ing each
result using the â¸¨for/monad+â¸© iterator. Therefore, every â€œcache hitâ€ on
â¸¨Â¢â¸¢outâ¸£â¸© is in one of two possible states: 1) we have already seen the
configuration, and the result is the oracle result, as desired; or 2) we have
already computed the â€œimprovedâ€ result (w.r.t. the oracle), and need not
recompute it.

To compute the least fixed-point â¸¨Â¢âºâ¸© for the evaluator â¸¨ev-cacheâ¸© we perform a
standard Kleene fixpoint iteration starting from the empty map, the bottom
element for the cache, as shown in Figure~\ref{f:fixing}.

The algorithm runs the caching evaluator â¸¨evalâ¸© on the given program â¸¨eâ¸© from
the initial environment and store. This is done inside of â¸¨mlfpâ¸©, a monadic
least fixed-point finder. After finding the least fixed-point, the final values
and store for the initial configuration â¸¨Ï‚â¸© are extracted and returned.

Termination of the least fixed-point is justified by the monotonicity of the
evaluator (it always returns an â€œimprovedâ€ oracle), and the finite domain of
the cache, which maps abstract configurations to pairs of values and stores,
all of which are finite.

\begin{figure} %{-{
\rfloat{â¸¨fix-cache@â¸©}
\begin{lstlisting}
Â¦ (define ((fix-cache eval) e)  
Â¦   (do Ï â† ask-env
Â¦       Ïƒ â† get-store
Â¦       Ï‚ â‰” (list e Ï Ïƒ)
Â¦       Â¢âº â† (mlfp (Î» (Â¢) 
Â¦              (do (put-cache-out âˆ…-map)
Â¦                  (put-store Ïƒ)
Â¦                  (local-cache-in Â¢ (eval e))
Â¦                  get-cache-out)))
Â¦       (for/monad+ ([vÃ—Ïƒ (Â¢âº Ï‚)])
Â¦         (do (put-store (cdr vÃ—Ïƒ))
Â¦             (return (car vÃ—Ïƒ))))))
Â¦ (define (mlfp f)
Â¦   (let loop ([x âˆ…-map])
Â¦     (do xâ€² â† (f x)
Â¦         (if (equal? xâ€² x)
Â¦             (return x)
Â¦             (loop xâ€²)))))
\end{lstlisting}
\caption{Finding Fixpoints in the Cache}
\label{f:fixing}
\end{figure} %}-}

With these peices in place we construct a complete interpreter:
\begin{lstlisting}
Â¦ (define (eval e)
Â¦   (mrun ((fix-cache (fix (ev-cache ev))) e)))
\end{lstlisting}
When linked with â¸¨Î´^â¸© and â¸¨alloc^â¸©, this interpreter is
a computable and sound abstraction of the original definitional interpreter:
â„‘â…
Â¦ > (rec f (Î» (x) (f x))
Â¦     (f 0))
â„‘,
Â¦ '()
â„‘;
Â¦ > (rec f (Î» (n) (if0 n 1 (* n (f (sub1 n)))))
Â¦     (fact 5))
â„‘,
Â¦ '(N)
â„‘;
Â¦ > (rec f (Î» (x) (if0 x 0 (if0 (f (sub1 x)) 2 3)))
Â¦      (f (add1 0)))
â„‘,
Â¦ '(0 2 3)
â„‘â†

% Let us now take stock of what we've got.
% We use the following monad stack, which adds a ``cache'' component,
% which will be a finite map from states to sets of values:
% \begin{lstlisting}
% Â¦ (ReaderT (FailT (StateT (NondetT (StateT+ ID)))))
% \end{lstlisting}
% 
% The â¸¨StateT+â¸© monad transformer provides operations
% â¸¨get-Â¢â¸© and â¸¨update-Â¢â€ºâ¸© for getting and updating the
% cache, respectively. It joins its finite maps by union of the range
% when â¸¨mplusâ¸© is called, because it cannot defer to an
% underlying monoid as the outer â¸¨StateTâ¸© does with
% â¸¨NondetTâ¸©.
% 
% Figure~\ref{f:ev-cache0} gives an â¸¨evâ¸©-wrapper that interposes
% itself on each recursive call to do the following steps:
% \begin{displayquote}
% Check if the current state is in the cache.  If it's in the cache, return all
% the results given in the cache.  If it's not, set the cache for the current
% state to the empty set, evaluate the expression, add the resulting value to the
% cache for the state, and return the result.
% \end{displayquote}
% 
% We can now define an evaluation function that mixes in â¸¨ev-cacheâ¸©:
% \begin{lstlisting}
% Â¦ (define (eval e)
% Â¦   (mrun ((fix (ev-cache ev)) e)))
% \end{lstlisting}
% 
% If we were to link this together with â¸¨alloc@â¸© and â¸¨Î´@â¸©, we'd obtain a concrete
% interpreter that either 1) produces the empty set because it encountered a
% loop, 2) produces a singleton result, or 3) diverges because it encounters an
% infinite set of states.  But if we were to link this together with â¸¨alloc^@â¸©
% and â¸¨Î´^@â¸©, we'd obtain an abstract interpreter that is \emph{total}: it
% terminates on all inputs.
% 
% To see why this, observe that for a given program there only a finite set of
% possible caches.  We have already seen that there are a finite set of states
% and values, so it follows that there are only a finite set of maps from states
% to sets of values.  Now notice that on each recursive call, either the state is
% in the cache and it returns immediately, or the cache grows.  So programs
% simply cannot run forever because that would imply the cache would grow
% forever.
% 
% It should be easy to see that if evaluating a state â¸¨Ï‚â¸© requires recursively
% evaluating that same state, it will now produce the empty set since the cache
% will be updated to map â¸¨Ï‚â¸© to â¸¨âˆ…â¸© before proceeding to the sub-expressions.
% 
% We can now see that the caching abstract interpreter halts on programs that
% loop (for simplicity, the cache and store are omitted from the printed
% results):
% â„‘â…
% Â¦ > (rec f (Î» (x) (f x)) (f 0))
% â„‘,
% Â¦ '()
% â„‘â†
% This accomplishes the goal of terminating on this example, and it even
% gives the right answer---the empty set---since this program produces
% no results.
% 
% It also works for recursive functions that terminate in the concrete,
% but have loops once abstracted:
% â„‘â…
% Â¦ > (rec fact (Î» (n)
% Â¦              (if0 n 1 (* n (fact (sub1 n)))))
% Â¦     (fact 5))
% â„‘,
% Â¦ '(N)
% â„‘â†
% 
% It may seem we've accomplished our goal of making a sound and
% decidable abstract interpreter.  However this approach is broken in
% general: it is not sound in the presence of abstraction.  The problem
% here is that when the interpreter reaches ``the same'' state it has
% seen before, what we mean by ``the same'' in the presence of
% abstraction is subtle.  For example, imagine evaluating a function
% application of some function â¸¨fâ¸© to an abstract value
% â¸¨'Nâ¸©.  Suppose in evaluating this application we encounter
% another application of â¸¨fâ¸© to â¸¨'Nâ¸©.  Is it the same
% application?  Well, yes and no.  It is the same \emph{abstract} state,
% however the abstract state stands for a set of concrete states; in
% this case, the application of â¸¨fâ¸© to all numbers.  So there are
% states stood for in the abstraction that are equal \emph{and} not
% equal.  In other words, in the presence of abstraction, when a loop is
% detected, there \emph{may} be a loop in the concrete interpretation.
% Our naive loop detection set-up however is assuming there \emph{must}
% be a loop.
% 
% We can demonstrate the problem with a simple counter-example to
% soundness:
% â„‘â…
% Â¦ > (rec f (Î» (x) 
% Â¦            (if0 x 0 (if0 (f (sub1 x)) 2 3)))
% Â¦      (f (add1 0)))
% â„‘,
% Â¦ '(0)
% â„‘â†
% 
% Concretely, this program returns â¸¨2â¸©, however with the
% combination of loop detection and abstraction, the abstract
% interpreter determines that this program produces â¸¨0â¸©, which is
% clearly unsound.
